{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape the news sentiments up to a year back for microsoft alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import calendar\n",
    "import os\n",
    "import logging\n",
    "# set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# create a file handler\n",
    "handler = logging.FileHandler('msft_news_scrape.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "# create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(handler)\n",
    "sns.set()\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def get_data(parameters):\n",
    "    endpoint = \"https://www.alphavantage.co/query\"\n",
    "    for _ in range(200):\n",
    "        parameters['apikey'] = ''.join(random.choices(string.ascii_uppercase + string.digits, k=15))\n",
    "        # Send a GET request to the API endpoint\n",
    "        response = requests.get(endpoint, params=parameters)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'Note' not in data: \n",
    "                break\n",
    "            logger.warning(f'API key {parameters[\"apikey\"]} has been used too many times. response note: {data[\"Note\"]}')\n",
    "            data = None\n",
    "            time.sleep(1)\n",
    "        else: \n",
    "            logger.error(f'API key {parameters[\"apikey\"]} has returned an error. response note: {response.json()}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_news_in_range(start_time: datetime, day_range: int = 100):\n",
    "    # create a folder to store the sentiments and ignore if it already exists\n",
    "    os.makedirs('sentiments', exist_ok=True)\n",
    "    sentiment_list = []\n",
    "    for i in tqdm(range(day_range)):\n",
    "        # repeat the process for ealiest and latest\n",
    "        for sort_by in ['LATEST', 'EARLIEST', 'RELEVANCE']:\n",
    "            # get the time range\n",
    "            time_to = (start_time - timedelta(days=i)).strftime('%Y%m%dT%H%M')\n",
    "            time_from = (start_time - timedelta(days=i+1)).strftime('%Y%m%dT%H%M')\n",
    "            parameters = {\n",
    "                \"function\": \"NEWS_SENTIMENT\",\n",
    "                'tickers': 'MSFT',\n",
    "                \"time_from\": time_from,\n",
    "                \"time_to\": time_to,\n",
    "                \"sort\": sort_by,\n",
    "                \"limit\": \"200\"\n",
    "            }\n",
    "            # get the news sentiment for the past week\n",
    "            sentiment = get_data(parameters)\n",
    "            if sentiment is None:\n",
    "                logger.error(f'Unnable to fetch sentiment data for {sort_by} from {time_from} to {time_to}')\n",
    "                continue\n",
    "            with open(os.path.join('sentiments', f'sentiments_{sort_by}_{time_from}.json'), 'w') as f:\n",
    "                json.dump(sentiment, f, indent=4)\n",
    "            # append the sentiment to the list\n",
    "            sentiment_list.append(sentiment)\n",
    "    return sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:05<00:00, 32.80s/it]\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    sent_df = pd.read_csv('datasets/msft_sentiments.csv').drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    # get the timedelta between the last date in the csv and the current date\n",
    "    day_range = (datetime.now() - pd.to_datetime(sent_df['time']).iloc[0]).days + 1\n",
    "except FileNotFoundError: \n",
    "    sent_df = pd.DataFrame()\n",
    "    day_range = 365\n",
    "\n",
    "start_time = datetime.now()\n",
    "# # get the datetime of the 10.10.2021\n",
    "# start_time = datetime.strptime('2.3.2022', '%d.%m.%Y')\n",
    "# day_range = 365\n",
    "\n",
    "# start sweeping from right now, for older sweeps change datetime to datetime.now() - timedelta(days=num_days_past)\n",
    "all_news = sweep_news_in_range(start_time, day_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e98acf34c3a3ed7ba9cef9bfd34c06994724c15667322623b0180eb3fbf1d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
