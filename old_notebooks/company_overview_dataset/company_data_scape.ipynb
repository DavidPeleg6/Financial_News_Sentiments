{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all fundamental data of a company\n",
    "\n",
    "Including:\n",
    "\n",
    "* Overview\n",
    "* Income Statement\n",
    "* Balance Sheet\n",
    "* Cash Flow\n",
    "* Earnings\n",
    "* Earnings Calender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import alpha_vantage\n",
    "except:\n",
    "    ! pip install alpha_vantage\n",
    "    import alpha_vantage\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import calendar\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import logging\n",
    "# set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# create a file handler\n",
    "handler = logging.FileHandler('company_overview_scrape.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "# create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(handler)\n",
    "sns.set()\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape date according to the function requested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO later on, pull only data about companies that are approaching their earnings call/quarter end</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'200DayMovingAverage': '253.79',\n",
      " '50DayMovingAverage': '245.05',\n",
      " '52WeekHigh': '313.66',\n",
      " '52WeekLow': '212.83',\n",
      " 'Address': 'ONE MICROSOFT WAY, REDMOND, WA, US',\n",
      " 'AnalystTargetPrice': '284.73',\n",
      " 'AssetType': 'Common Stock',\n",
      " 'Beta': '0.916',\n",
      " 'BookValue': '24.59',\n",
      " 'CIK': '789019',\n",
      " 'Country': 'USA',\n",
      " 'Currency': 'USD',\n",
      " 'Description': 'Microsoft Corporation is an American multinational technology '\n",
      "                'company which produces computer software, consumer '\n",
      "                'electronics, personal computers, and related services. Its '\n",
      "                'best known software products are the Microsoft Windows line '\n",
      "                'of operating systems, the Microsoft Office suite, and the '\n",
      "                'Internet Explorer and Edge web browsers. Its flagship '\n",
      "                'hardware products are the Xbox video game consoles and the '\n",
      "                'Microsoft Surface lineup of touchscreen personal computers. '\n",
      "                'Microsoft ranked No. 21 in the 2020 Fortune 500 rankings of '\n",
      "                'the largest United States corporations by total revenue; it '\n",
      "                \"was the world's largest software maker by revenue as of 2016. \"\n",
      "                'It is considered one of the Big Five companies in the U.S. '\n",
      "                'information technology industry, along with Google, Apple, '\n",
      "                'Amazon, and Facebook.',\n",
      " 'DilutedEPSTTM': '9',\n",
      " 'DividendDate': '2023-03-09',\n",
      " 'DividendPerShare': '2.6',\n",
      " 'DividendYield': '0.0103',\n",
      " 'EBITDA': '97945002000',\n",
      " 'EPS': '9',\n",
      " 'EVToEBITDA': '18.55',\n",
      " 'EVToRevenue': '9.21',\n",
      " 'ExDividendDate': '2023-02-15',\n",
      " 'Exchange': 'NASDAQ',\n",
      " 'FiscalYearEnd': 'June',\n",
      " 'ForwardPE': '27.03',\n",
      " 'GrossProfitTTM': '135620000000',\n",
      " 'Industry': 'SERVICES-PREPACKAGED SOFTWARE',\n",
      " 'LatestQuarter': '2022-12-31',\n",
      " 'MarketCapitalization': '1958463799000',\n",
      " 'Name': 'Microsoft Corporation',\n",
      " 'OperatingMarginTTM': '0.41',\n",
      " 'PEGRatio': '2.275',\n",
      " 'PERatio': '29.23',\n",
      " 'PriceToBookRatio': '11.05',\n",
      " 'PriceToSalesRatioTTM': '9.14',\n",
      " 'ProfitMargin': '0.331',\n",
      " 'QuarterlyEarningsGrowthYOY': '-0.113',\n",
      " 'QuarterlyRevenueGrowthYOY': '0.02',\n",
      " 'ReturnOnAssetsTTM': '0.148',\n",
      " 'ReturnOnEquityTTM': '0.393',\n",
      " 'RevenuePerShareTTM': '27.33',\n",
      " 'RevenueTTM': '204093997000',\n",
      " 'Sector': 'TECHNOLOGY',\n",
      " 'SharesOutstanding': '7443800000',\n",
      " 'Symbol': 'MSFT',\n",
      " 'TrailingPE': '29.23'}\n"
     ]
    }
   ],
   "source": [
    "# functions = ['OVERVIEW', 'INCOME_STATEMENT', 'BALANCE_SHEET', 'CASH_FLOW', 'EARNINGS']\n",
    "functions = ['EARNINGS']\n",
    "\n",
    "def company_data(function: str = 'OVERVIEW', company_symbol: str = 'MSFT'):\n",
    "    endpoint = \"https://www.alphavantage.co/query\"\n",
    "    parameters = {\n",
    "        \"function\": function,\n",
    "        \"symbol\": company_symbol,\n",
    "        \"horizon\": \"12month\"\n",
    "    }\n",
    "    for _ in range(100):\n",
    "        parameters['apikey'] = ''.join(random.choices(string.ascii_uppercase + string.digits, k=15))\n",
    "        # Send a GET request to the API endpoint\n",
    "        response = requests.get(endpoint, params=parameters)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'Note' not in data: \n",
    "                break\n",
    "            logger.warning(f'API key {parameters[\"apikey\"]} has been used too many times. response note: {data[\"Note\"]}')\n",
    "            data = None\n",
    "            time.sleep(1)\n",
    "        else: \n",
    "            logger.error(f'API key {parameters[\"apikey\"]} has returned an error. response note: {response.json()}')\n",
    "    return data\n",
    "\n",
    "# msft_data_horizon = company_data(function='OVERVIEW', company_symbol='MSFT')\n",
    "# pprint(msft_data_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep over all stock tickers and pull daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# get stock price for all tickers\n",
    "def get_companies_data(stocks_to_watch: list):\n",
    "    \"\"\"Get stock price for all tickers in the list\"\"\"\n",
    "    os.makedirs('overview', exist_ok=True)\n",
    "    # only get stock price for stocks that are not in the directory\n",
    "    seen_stocks = [f.split('.')[0] for f in os.listdir('overview') if os.path.isfile(os.path.join('overview', f))]\n",
    "    for ticker in tqdm([t for t in stocks_to_watch if t not in seen_stocks]):\n",
    "        data = [company_data(func, ticker) for func in functions]\n",
    "        # check whether any of the items in data is None and get the index of the first None item\n",
    "        if any(d is None for d in data):\n",
    "            logger.error(f'Unnable to fetch {functions[data.index(None)]} data for {ticker}')\n",
    "            continue\n",
    "        with open(f'overview/{ticker}.json', 'w') as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "\n",
    "# get_companies_data(['MSFT'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset based on the most mentioned stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6322"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pd dataframe from csv\n",
    "tickers = pd.read_csv('../tickers.csv').sort_values('symbol')\n",
    "# load the sentiment data\n",
    "sentiment_df = pd.read_csv('../news_sentiment_dataset/sentiments.csv')\n",
    "# get a list of tickers sorted by frequency\n",
    "ticker_list = sentiment_df['ticker'].value_counts().index.tolist()\n",
    "len(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'META', 'MSFT', 'GOOG', 'AAPL', 'BLK', 'BCS', 'AMZN', 'BBBY', 'NVDA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 118/11113 [18:14<28:19:29,  9.27s/it]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m tickers_to_watch \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ticker_list \u001b[39mif\u001b[39;00m t \u001b[39min\u001b[39;00m tickers_to_watch] \u001b[39m+\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tickers_to_watch \u001b[39mif\u001b[39;00m t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ticker_list]\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(tickers_to_watch[:\u001b[39m10\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m get_companies_data(tickers_to_watch)\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36mget_companies_data\u001b[1;34m(stocks_to_watch)\u001b[0m\n\u001b[0;32m      6\u001b[0m seen_stocks \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39moverview\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39moverview\u001b[39m\u001b[39m'\u001b[39m, f))]\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tqdm([t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m stocks_to_watch \u001b[39mif\u001b[39;00m t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m seen_stocks]):\n\u001b[1;32m----> 8\u001b[0m     data \u001b[39m=\u001b[39m [company_data(func, ticker) \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m functions]\n\u001b[0;32m      9\u001b[0m     \u001b[39m# check whether any of the items in data is None and get the index of the first None item\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(d \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data):\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m seen_stocks \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39moverview\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39moverview\u001b[39m\u001b[39m'\u001b[39m, f))]\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tqdm([t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m stocks_to_watch \u001b[39mif\u001b[39;00m t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m seen_stocks]):\n\u001b[1;32m----> 8\u001b[0m     data \u001b[39m=\u001b[39m [company_data(func, ticker) \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m functions]\n\u001b[0;32m      9\u001b[0m     \u001b[39m# check whether any of the items in data is None and get the index of the first None item\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(d \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data):\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mcompany_data\u001b[1;34m(function, company_symbol)\u001b[0m\n\u001b[0;32m     22\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[1;32m---> 24\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAPI key \u001b[39m\u001b[39m{\u001b[39;00mparameters[\u001b[39m\"\u001b[39m\u001b[39mapikey\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m has returned an error. response note: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mjson()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "tickers_to_watch = tickers['symbol'].unique()\n",
    "# sort tickers_to_watch according to the order of ticker_list and add the rest of the tickers\n",
    "tickers_to_watch = [t for t in ticker_list if t in tickers_to_watch] + [t for t in tickers_to_watch if t not in ticker_list]\n",
    "print(tickers_to_watch[:10])\n",
    "get_companies_data(tickers_to_watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "322a509557a274cb16a0e1e68450414eb651dbdd02be71d467608ec080fac03e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
