{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the Alpha Vantage api and collect daily prices in the backgroung\n",
    "\n",
    "## Get daily financial data of all companies, going a quarter back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import alpha_vantage\n",
    "except:\n",
    "    ! pip install alpha_vantage\n",
    "    import alpha_vantage\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import calendar\n",
    "import os\n",
    "import logging\n",
    "# set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# create a file handler\n",
    "handler = logging.FileHandler('price_scrape.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "# create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(handler)\n",
    "sns.set()\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all keys for the alpha vantage api and multiply it by 5 since each key is allowed up to 5 requests per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../keys.json') as f:\n",
    "    keys = json.load(f) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download the dataset for all stocks\n",
    "\n",
    "Load the CSV of all tickers in the us stock market and use it to get the price of all stocks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">TODO order the stock scraping process according to highest exchange volume or market cap mentioned in company overview dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def get_stockprice(company_symbol: str = 'MSFT'):\n",
    "    endpoint = \"https://www.alphavantage.co/query\"\n",
    "    parameters = {\n",
    "        \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
    "        \"symbol\": company_symbol,\n",
    "        \"outputsize\": 'full'\n",
    "    }\n",
    "    for _ in range(100):\n",
    "        parameters['apikey'] = ''.join(random.choices(string.ascii_uppercase + string.digits, k=15))\n",
    "        # Send a GET request to the API endpoint\n",
    "        response = requests.get(endpoint, params=parameters)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'Note' not in data: \n",
    "                break\n",
    "            logger.warning(f'API key {parameters[\"apikey\"]} has been used too many times. response note: {data[\"Note\"]}')\n",
    "            data = None\n",
    "            time.sleep(1)\n",
    "        else: \n",
    "            logger.error(f'API key {parameters[\"apikey\"]} has returned an error. response note: {response.json()}')\n",
    "    return data\n",
    "\n",
    "# pprint(get_stockprice('MSFT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep over all stock tickers and pull daily data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO later on, combine the price dataset with the sentiment dataset such that for each stock price you have the daily averaged sentiment as well</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stock price for all tickers\n",
    "def get_stockprice_all(stocks_to_watch: list):\n",
    "    os.makedirs('prices', exist_ok=True)\n",
    "    # only get stock price for stocks that are not in the directory\n",
    "    seen_stocks = [f.split('.')[0] for f in os.listdir('prices') if os.path.isfile(os.path.join('prices', f))]\n",
    "    for ticker in tqdm([t for t in stocks_to_watch if t not in seen_stocks]):\n",
    "        data = get_stockprice(ticker)\n",
    "        if data is None: \n",
    "            logger.error(f'Unnable to fetch data for {ticker}')\n",
    "            continue\n",
    "        with open(f'prices/{ticker}.json', 'w') as outfile:\n",
    "            json.dump(data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>assetType</th>\n",
       "      <th>ipoDate</th>\n",
       "      <th>ipoYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>Stock</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corp</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>AAA</td>\n",
       "      <td>AXS FIRST PRIORITY CLO BOND ETF</td>\n",
       "      <td>NYSE ARCA</td>\n",
       "      <td>ETF</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Goldman Sachs Physical Gold ETF</td>\n",
       "      <td>BATS</td>\n",
       "      <td>ETF</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>AAC</td>\n",
       "      <td>Ares Acquisition Corporation - Class A</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>Stock</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                                    name   exchange assetType  \\\n",
       "1757      A                Agilent Technologies Inc       NYSE     Stock   \n",
       "5188     AA                              Alcoa Corp       NYSE     Stock   \n",
       "7179    AAA        AXS FIRST PRIORITY CLO BOND ETF   NYSE ARCA       ETF   \n",
       "6080   AAAU         Goldman Sachs Physical Gold ETF       BATS       ETF   \n",
       "8092    AAC  Ares Acquisition Corporation - Class A       NYSE     Stock   \n",
       "\n",
       "         ipoDate  ipoYear  \n",
       "1757  1999-11-18     1999  \n",
       "5188  2016-10-18     2016  \n",
       "7179  2020-09-09     2020  \n",
       "6080  2018-08-15     2018  \n",
       "8092  2021-03-25     2021  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pd dataframe from csv\n",
    "tickers = pd.read_csv('../tickers.csv').sort_values('symbol')\n",
    "tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the news sentiment dataset and sort the tickers according to most frequent mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the sentiment data\n",
    "sentiment_df = pd.read_csv('../news_sentiment_dataset/sentiments.csv')\n",
    "# get a list of tickers sorted by frequency\n",
    "sentiment_ticker_list = sentiment_df['ticker'].value_counts().index.tolist()\n",
    "len(sentiment_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'META', 'MSFT', 'GOOG', 'AAPL', 'BLK', 'BCS', 'AMZN', 'BBBY', 'NVDA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/11114 [08:54<29:20:21,  9.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m tickers_to_watch \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m sentiment_ticker_list \u001b[39mif\u001b[39;00m t \u001b[39min\u001b[39;00m tickers_to_watch] \u001b[39m+\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tickers_to_watch \u001b[39mif\u001b[39;00m t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sentiment_ticker_list]\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(tickers_to_watch[:\u001b[39m10\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m get_stockprice_all(tickers_to_watch)\n",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m, in \u001b[0;36mget_stockprice_all\u001b[1;34m(stocks_to_watch)\u001b[0m\n\u001b[0;32m      5\u001b[0m seen_stocks \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mprices\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mprices\u001b[39m\u001b[39m'\u001b[39m, f))]\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m tqdm([t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m stocks_to_watch \u001b[39mif\u001b[39;00m t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m seen_stocks]):\n\u001b[1;32m----> 7\u001b[0m     data \u001b[39m=\u001b[39m get_stockprice(ticker)\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \n\u001b[0;32m      9\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnnable to fetch data for \u001b[39m\u001b[39m{\u001b[39;00mticker\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m, in \u001b[0;36mget_stockprice\u001b[1;34m(company_symbol)\u001b[0m\n\u001b[0;32m     20\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAPI key \u001b[39m\u001b[39m{\u001b[39;00mparameters[\u001b[39m\"\u001b[39m\u001b[39mapikey\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m has been used too many times. response note: \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m\"\u001b[39m\u001b[39mNote\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m     24\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAPI key \u001b[39m\u001b[39m{\u001b[39;00mparameters[\u001b[39m\"\u001b[39m\u001b[39mapikey\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m has returned an error. response note: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mjson()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tickers_to_watch = tickers['symbol'].unique()\n",
    "# sort tickers_to_watch according to the order of ticker_list and add the rest of the tickers\n",
    "tickers_to_watch = [t for t in sentiment_ticker_list if t in tickers_to_watch] + [t for t in tickers_to_watch if t not in sentiment_ticker_list]\n",
    "print(tickers_to_watch[:10])\n",
    "get_stockprice_all(tickers_to_watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "322a509557a274cb16a0e1e68450414eb651dbdd02be71d467608ec080fac03e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
